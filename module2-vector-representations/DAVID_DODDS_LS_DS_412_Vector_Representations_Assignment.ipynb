{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "                \n",
    "df = pd.read_csv('./data/job_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(desc):\n",
    "    soup = BeautifulSoup(desc)\n",
    "    return soup.get_text()\n",
    "df['clean_desc'] = df['description'].apply(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        description  \\\n",
       "0      0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1      1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2      2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3      3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4      4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                          clean_desc  \n",
       "0  b\"Job Requirements:\\nConceptual understanding ...  \n",
       "1  b'Job Description\\n\\nAs a Data Scientist 1, yo...  \n",
       "2  b'As a Data Scientist you will be working on c...  \n",
       "3  b'$4,969 - $6,756 a monthContractUnder the gen...  \n",
       "4  b'Location: USA \\xe2\\x80\\x93 multiple location...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = df.rename(columns={'Unnamed: 0':'index'})\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0['clean_desc'][0].replace(\"b\",'',1).replace(r\"\\n\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmings = []\n",
    "\n",
    "for x in range(len(df0['clean_desc'])):\n",
    "    trimmed = df0['clean_desc'][x].replace(\"b\",'',1)\n",
    "    trimmed0 = trimmed.replace(r\"\\n\", ' ')\n",
    "    trimmed1 = trimmed0.replace(\"\\\\\", ' ')\n",
    "    trimmed2 = trimmed1.replace(r\"/\", ' ')\n",
    "    trimmed3 = trimmed2.replace(r\"'\", ' ')\n",
    "    trimmed4 = trimmed3.replace(r'\"', ' ')\n",
    "    trimmed5 = trimmed4.replace(' x/s/s', '')\n",
    "    trimmed6 = trimmed5.replace(' xa8', '')\n",
    "    trimmed7 = trimmed6.replace(' xe2', '')\n",
    "    trimmed8 = trimmed7.replace(' x80', '')\n",
    "    trimmed9 = trimmed8.replace(' xa6', '')\n",
    "    trimmed10 = trimmed9.replace(' x99', '')\n",
    "\n",
    "    trimmings.append(trimmed10)\n",
    "\n",
    "df0['trimmed'] = trimmings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Location: USA  x93 multiple locations 2+ years of Analytics experience Understand business requirements and technical requirements Can handle data extraction, preparation and transformation Create and implement data models '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0['trimmed'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_jargon = [\n",
    "    ' ','datum','data','science','scientist'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(stop_jargon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_desc</th>\n",
       "      <th>trimmed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "      <td>Job Requirements: Conceptual understanding in...</td>\n",
       "      <td>[job, requirements, conceptual, understand, un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "      <td>Job Description  As a Data Scientist 1, you w...</td>\n",
       "      <td>[job, description, 1, 1, 1, help, help, build,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "      <td>As a Data Scientist you will be working on co...</td>\n",
       "      <td>[work, work, consult, consult, consult, consul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
       "      <td>$4,969 - $6,756 a monthContractUnder the gene...</td>\n",
       "      <td>[4969, 4969, 6756, 6756, monthcontractunder, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n",
       "      <td>Location: USA  x93 multiple locations 2+ year...</td>\n",
       "      <td>[location, usa, x93, multiple, location, 2, ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        description  \\\n",
       "0      0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1      1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2      2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3      3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4      4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \\\n",
       "0               Data scientist    \n",
       "1              Data Scientist I   \n",
       "2  Data Scientist - Entry Level   \n",
       "3                Data Scientist   \n",
       "4                Data Scientist   \n",
       "\n",
       "                                          clean_desc  \\\n",
       "0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2  b'As a Data Scientist you will be working on c...   \n",
       "3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "\n",
       "                                             trimmed  \\\n",
       "0   Job Requirements: Conceptual understanding in...   \n",
       "1   Job Description  As a Data Scientist 1, you w...   \n",
       "2   As a Data Scientist you will be working on co...   \n",
       "3   $4,969 - $6,756 a monthContractUnder the gene...   \n",
       "4   Location: USA  x93 multiple locations 2+ year...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [job, requirements, conceptual, understand, un...  \n",
       "1  [job, description, 1, 1, 1, help, help, build,...  \n",
       "2  [work, work, consult, consult, consult, consul...  \n",
       "3  [4969, 4969, 6756, 6756, monthcontractunder, m...  \n",
       "4  [location, usa, x93, multiple, location, 2, ye...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df0['trimmed']):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.is_stop == False) & (token.is_punct == False):\n",
    "            lowers = re.sub('[^a-zA-z 0-9]', '', token.lemma_).lower()\n",
    "        if lowers not in STOP_WORDS:\n",
    "            doc_tokens.append(lowers)\n",
    "        \n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "df0['tokens'] = tokens\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "vect= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Job Requirements: Conceptual understanding in Machine Learning models like Nai xc2ve Bayes, K-Means, SVM, Apriori, Linear  Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them Intermediate to expert level coding skills in Python R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role) Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R Ability to communicate Model findings to both Technical and Non-Technical stake holders Hands on experience in SQL Hive or similar programming language Must show past work via GitHub, Kaggle or any other published article Master s degree in Statistics Mathematics Computer Science or any other quant specific field. Apply Now ',\n",
       " ' Job Description  As a Data Scientist 1, you will help us build machine learning models, data pipelines, and micro-services to help our clients navigate their healthcare journey. You will do so by empowering and improving the next generation of Accolade Applications and user experiences. A day in the life Work with a small agile team to design and develop mobile applications in an iterative fashion. Work with a tight-knit group of development team members in Seattle. Contribute to best practices and help guide the future of our applications. Operates effectively as a collaborative member of the development team. Operates effectively as an individual for quick turnaround of enhancements and fixes. Responsible for meeting expectations and deliverables on time with high quality. Drive and implement new features within our mobile applications. Perform thorough manual testing and writing test cases that cover all areas. Identify new development tools approaches that will increase code quality, efficiency, and best practices. Develop and champion the the development processes, coding style guidelines, and architectural designs necessary to innovate and maintain great product quality. Effectively turns design documents and graphics into performant, usable UI. Demonstrates creative, technical, and analytical skills. Demonstrates ability to communicate effectively in both technical and business environments  Qualifications  What we are looking for Masters Degree in Computer Science, Math, or related field. Computer Science fundamentals, as illustrated through algorithm design, problem solving, and complexity analysis. Must have 1+ year real-world experience developing and deploying micro-services or data pipelines Must have a fundamental understanding of key machine learning concepts, such as accuracy measures, cross-validation, and open source machine learning libraries Fluent in Python and SQL Proficient with writing unit functional tests and familiar with automation frameworks Experience with cloud infrastructure, such as AWS or Azure, is a plus. Experience with distributed data pipelines, such as a Spark, is a plus. Strong written and oral communication skills. Desire and willingness to work in an Agile, collaborative, innovative, flexible, and team-oriented environment Hands-on, detail-oriented, methodical & inquisitive A motivated self-starter with a solid level of experience that quickly grasps complex challenges A skillful communicator with experience working with technical management teams  A service oriented person who thinks  Customer First  Fast fail entrepreneurial spirit Thrives in a fast-paced environment where continuous improvement is the norm and the bar for quality is extremely high Excited by the challenges of working in a product team undergoing rapid, international growth Additional Information  What is important to us Creating an enduring company that is hyper-focused on our culture and making a meaningful impact in the lives of our employees, members and customers. The secret to our success is: We find joy and purpose in serving others Making a difference in our members and customers lives is what we do. Even when its hard, we do the right thing for the right reasons. We are strong individually and together, were powerful Trusting in our colleagues and embracing their different backgrounds and experiences enable us to solve tough problems in creative ways, having fun along the way. We roll up our sleeves and get stuff done Results motivate us. And we aren  t afraid of the hard work or tough decisions needed to get us there. Were boldly and relentlessly reinventing healthcare We  re curious and act big - not afraid to knock down barriers or take calculated risks to change the world, one person at a time. All your information will be kept confidential according to EEO guidelines. ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmings[:2]\n",
    "\n",
    "# rawtext = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'requirements',\n",
       " 'conceptual',\n",
       " 'understand',\n",
       " 'understand',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'model',\n",
       " 'like',\n",
       " 'nai',\n",
       " 'xc2ve',\n",
       " 'bayes',\n",
       " 'kmeans',\n",
       " 'svm',\n",
       " 'apriori',\n",
       " 'linear',\n",
       " 'logistic',\n",
       " 'regression',\n",
       " 'neural',\n",
       " 'random',\n",
       " 'forests',\n",
       " 'decision',\n",
       " 'trees',\n",
       " 'knn',\n",
       " 'knn',\n",
       " 'knn',\n",
       " 'handson',\n",
       " 'experience',\n",
       " 'experience',\n",
       " 'experience',\n",
       " 'experience',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " 'intermediate',\n",
       " 'intermediate',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'code',\n",
       " 'skill',\n",
       " 'skill',\n",
       " 'python',\n",
       " 'r',\n",
       " 'ability',\n",
       " 'ability',\n",
       " 'write',\n",
       " 'functions',\n",
       " 'clean',\n",
       " 'clean',\n",
       " 'efficient']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1tokens = []\n",
    "\n",
    "for listobj in df0['tokens']:\n",
    "    for w in range(len(listobj)):\n",
    "        d1tokens.append(listobj[w])\n",
    "\n",
    "d1tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(d1tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.transform(trimmings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_df = pd.DataFrame(\n",
    "    dtm.todense(),\n",
    "    columns=vect.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 8507)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>02</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>030</th>\n",
       "      <th>030547069</th>\n",
       "      <th>04</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zf</th>\n",
       "      <th>zfs</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zogsports</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurichs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  02  02115  03  030  030547069  04  06366  08  10  ...  zf  zfs  zheng  \\\n",
       "0   0   0      0   0    0          0   0      0   0   0  ...   0    0      0   \n",
       "1   0   0      0   0    0          0   0      0   0   0  ...   0    0      0   \n",
       "2   0   0      0   0    0          0   0      0   0   0  ...   0    0      0   \n",
       "3   0   0      0   0    0          0   0      0   0   0  ...   0    0      1   \n",
       "4   0   0      0   0    0          0   0      0   0   0  ...   0    0      0   \n",
       "\n",
       "   zillow  zogsports  zone  zoom  zuckerberg  zurich  zurichs  \n",
       "0       0          0     0     0           0       0        0  \n",
       "1       0          0     0     0           0       0        0  \n",
       "2       0          0     0     0           0       0        0  \n",
       "3       0          0     0     0           0       0        0  \n",
       "4       0          0     0     0           0       0        0  \n",
       "\n",
       "[5 rows x 8507 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dtm_df.shape)\n",
    "dtm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(docs):\n",
    "    word_counts = Counter()\n",
    "    appears_in = Counter()\n",
    "    \n",
    "    total_docs = len(docs)\n",
    "    \n",
    "    for doc in docs:\n",
    "        word_counts.update(doc)\n",
    "        appears_in.update(set(doc))\n",
    "    \n",
    "    temp = zip(word_counts.keys(), word_counts.values())\n",
    "    \n",
    "    wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "    \n",
    "    wc['rank'] = wc['count'].rank(\n",
    "        method='first', ascending=False\n",
    "    )\n",
    "    total = wc['count'].sum()\n",
    "    \n",
    "    wc['pct_total'] = wc['count'].apply(\n",
    "        lambda x: x/total\n",
    "    )\n",
    "    \n",
    "    wc = wc.sort_values(by='rank')\n",
    "    wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "    \n",
    "    t2 = zip(appears_in.keys(), appears_in.values())\n",
    "    ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "    wc = ac.merge(wc, on='word')\n",
    "    \n",
    "    wc['appears_in_pct'] = wc['appears_in'].apply(\n",
    "       lambda x: x/total_docs \n",
    "    )\n",
    "    \n",
    "    return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>appears_in</th>\n",
       "      <th>count</th>\n",
       "      <th>rank</th>\n",
       "      <th>pct_total</th>\n",
       "      <th>cul_pct_total</th>\n",
       "      <th>appears_in_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>experience</td>\n",
       "      <td>410</td>\n",
       "      <td>3542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.962441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>work</td>\n",
       "      <td>378</td>\n",
       "      <td>3139</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.016020</td>\n",
       "      <td>0.034098</td>\n",
       "      <td>0.887324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>team</td>\n",
       "      <td>362</td>\n",
       "      <td>2427</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.849765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>business</td>\n",
       "      <td>324</td>\n",
       "      <td>1527</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>0.054278</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>model</td>\n",
       "      <td>298</td>\n",
       "      <td>1513</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.699531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>analysis</td>\n",
       "      <td>313</td>\n",
       "      <td>1248</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.068369</td>\n",
       "      <td>0.734742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>product</td>\n",
       "      <td>256</td>\n",
       "      <td>1152</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.074248</td>\n",
       "      <td>0.600939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>learn</td>\n",
       "      <td>308</td>\n",
       "      <td>1122</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.005726</td>\n",
       "      <td>0.079975</td>\n",
       "      <td>0.723005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ability</td>\n",
       "      <td>248</td>\n",
       "      <td>1085</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.085512</td>\n",
       "      <td>0.582160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>analytics</td>\n",
       "      <td>249</td>\n",
       "      <td>1043</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.090835</td>\n",
       "      <td>0.584507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>build</td>\n",
       "      <td>293</td>\n",
       "      <td>1027</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0.096077</td>\n",
       "      <td>0.687793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>opportunity</td>\n",
       "      <td>282</td>\n",
       "      <td>1009</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.101226</td>\n",
       "      <td>0.661972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>solution</td>\n",
       "      <td>202</td>\n",
       "      <td>889</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.105764</td>\n",
       "      <td>0.474178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>211</td>\n",
       "      <td>874</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.110224</td>\n",
       "      <td>0.495305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>insight</td>\n",
       "      <td>202</td>\n",
       "      <td>858</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.474178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>year</td>\n",
       "      <td>301</td>\n",
       "      <td>836</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.118870</td>\n",
       "      <td>0.706573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>company</td>\n",
       "      <td>219</td>\n",
       "      <td>830</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.123106</td>\n",
       "      <td>0.514085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>help</td>\n",
       "      <td>263</td>\n",
       "      <td>821</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.127296</td>\n",
       "      <td>0.617371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>understand</td>\n",
       "      <td>225</td>\n",
       "      <td>810</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.131430</td>\n",
       "      <td>0.528169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>technology</td>\n",
       "      <td>246</td>\n",
       "      <td>804</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.135533</td>\n",
       "      <td>0.577465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  appears_in  count  rank  pct_total  cul_pct_total  \\\n",
       "46     experience         410   3542   1.0   0.018077       0.018077   \n",
       "45           work         378   3139   2.0   0.016020       0.034098   \n",
       "137          team         362   2427   3.0   0.012387       0.046484   \n",
       "263      business         324   1527   4.0   0.007793       0.054278   \n",
       "60          model         298   1513   5.0   0.007722       0.062000   \n",
       "114      analysis         313   1248   6.0   0.006369       0.068369   \n",
       "206       product         256   1152   7.0   0.005879       0.074248   \n",
       "278         learn         308   1122   8.0   0.005726       0.079975   \n",
       "23        ability         248   1085   9.0   0.005537       0.085512   \n",
       "322     analytics         249   1043  10.0   0.005323       0.090835   \n",
       "189         build         293   1027  11.0   0.005241       0.096077   \n",
       "390   opportunity         282   1009  12.0   0.005150       0.101226   \n",
       "780      solution         202    889  13.0   0.004537       0.105764   \n",
       "1246    knowledge         211    874  14.0   0.004461       0.110224   \n",
       "560       insight         202    858  15.0   0.004379       0.114603   \n",
       "127          year         301    836  16.0   0.004267       0.118870   \n",
       "270       company         219    830  17.0   0.004236       0.123106   \n",
       "299          help         263    821  18.0   0.004190       0.127296   \n",
       "37     understand         225    810  19.0   0.004134       0.131430   \n",
       "923    technology         246    804  20.0   0.004103       0.135533   \n",
       "\n",
       "      appears_in_pct  \n",
       "46          0.962441  \n",
       "45          0.887324  \n",
       "137         0.849765  \n",
       "263         0.760563  \n",
       "60          0.699531  \n",
       "114         0.734742  \n",
       "206         0.600939  \n",
       "278         0.723005  \n",
       "23          0.582160  \n",
       "322         0.584507  \n",
       "189         0.687793  \n",
       "390         0.661972  \n",
       "780         0.474178  \n",
       "1246        0.495305  \n",
       "560         0.474178  \n",
       "127         0.706573  \n",
       "270         0.514085  \n",
       "299         0.617371  \n",
       "37          0.528169  \n",
       "923         0.577465  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = count(df0['tokens'])\n",
    "wc.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 non</th>\n",
       "      <th>00 preferred</th>\n",
       "      <th>000</th>\n",
       "      <th>000 100</th>\n",
       "      <th>000 125</th>\n",
       "      <th>000 350</th>\n",
       "      <th>000 85</th>\n",
       "      <th>000 annually</th>\n",
       "      <th>000 associates</th>\n",
       "      <th>...</th>\n",
       "      <th>zuckerberg 2015</th>\n",
       "      <th>zuckerberg initiative</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurich american</th>\n",
       "      <th>zurich customers</th>\n",
       "      <th>zurich does</th>\n",
       "      <th>zurich north</th>\n",
       "      <th>zurich place</th>\n",
       "      <th>zurichs</th>\n",
       "      <th>zurichs predictive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  00 non  00 preferred  000  000 100  000 125  000 350  000 85  \\\n",
       "0  0.0     0.0           0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "1  0.0     0.0           0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "2  0.0     0.0           0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "3  0.0     0.0           0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "4  0.0     0.0           0.0  0.0      0.0      0.0      0.0     0.0   \n",
       "\n",
       "   000 annually  000 associates  ...  zuckerberg 2015  zuckerberg initiative  \\\n",
       "0           0.0             0.0  ...              0.0                    0.0   \n",
       "1           0.0             0.0  ...              0.0                    0.0   \n",
       "2           0.0             0.0  ...              0.0                    0.0   \n",
       "3           0.0             0.0  ...              0.0                    0.0   \n",
       "4           0.0             0.0  ...              0.0                    0.0   \n",
       "\n",
       "   zurich  zurich american  zurich customers  zurich does  zurich north  \\\n",
       "0     0.0              0.0               0.0          0.0           0.0   \n",
       "1     0.0              0.0               0.0          0.0           0.0   \n",
       "2     0.0              0.0               0.0          0.0           0.0   \n",
       "3     0.0              0.0               0.0          0.0           0.0   \n",
       "4     0.0              0.0               0.0          0.0           0.0   \n",
       "\n",
       "   zurich place  zurichs  zurichs predictive  \n",
       "0           0.0      0.0                 0.0  \n",
       "1           0.0      0.0                 0.0  \n",
       "2           0.0      0.0                 0.0  \n",
       "3           0.0      0.0                 0.0  \n",
       "4           0.0      0.0                 0.0  \n",
       "\n",
       "[5 rows x 75192 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,2),\n",
    "    max_df=.99,\n",
    "    min_df=.001\n",
    ")\n",
    "\n",
    "dtm0 = tfidf.fit_transform(trimmings)\n",
    "\n",
    "dtm0_df = pd.DataFrame(\n",
    "    dtm0.todense(), columns=tfidf.get_feature_names()\n",
    ")\n",
    "\n",
    "dtm0_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  00  \\\n",
      "4 0.000000000000000000000000000000000000000000000...   \n",
      "\n",
      "                                              00 non  \\\n",
      "4 0.000000000000000000000000000000000000000000000...   \n",
      "\n",
      "                                        00 preferred  \\\n",
      "4 0.000000000000000000000000000000000000000000000...   \n",
      "\n",
      "                                                 000  \\\n",
      "4 0.000000000000000000000000000000000000000000000...   \n",
      "\n",
      "                                             000 100  \n",
      "4 0.000000000000000000000000000000000000000000000...  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context(\n",
    "    'display.float_format', '{:0.50f}'.format\n",
    "):\n",
    "    print(dtm0_df.iloc[4:5, :5])\n",
    "\n",
    "# THESE VECTORS ARE TINY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='ball_tree')\n",
    "nn.fit(dtm0_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.26290975, 1.31038307, 1.33774465, 1.3452615 ]]),\n",
       " array([[  8, 419, 226, 129,  14]], dtype=int64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm0_df.iloc[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' MS in a quantitative discipline such as Statistics, Mathematics, Physics, Engineering, Computer Science or Economics5+ years work experienceProficiency in at least one statistical software package such as Python, R or MatlabExpertise using SQL for acquiring and transforming dataOutstanding quantitative modeling and statistical analysis skillsExcellent verbal and written communication skills with '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmings[8][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Bachelors or Masters degree in a quantitative field such as Statistics, Applied Mathematics, Physics, Engineering, Computer Science, or Economics 2+ years of relevant working experience in an analytical role involving data extraction, analysis, and communication 2+ years of experience with data querying languages (e.g. SQL, Hadoop Hive) and statistical mathematical software (e.g. R, Weka, Matlab,'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmings[419][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_job = [\"\"\"\n",
    "    Junior Machine Learning Engineer to work in a Machine\n",
    "    Learning team solving problems unique to geothermal\n",
    "    energy production. Must be willing to do site visits at\n",
    "    facilities throughout the west coast. Remote option\n",
    "    available.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mtrx = tfidf.transform(ideal_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vec = new_mtrx.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.36018599, 1.36480238, 1.36830694, 1.37023951, 1.37269608]]),\n",
       " array([[  2, 261, 173, 297, 283]], dtype=int64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' As a Data Scientist you will be working on consulting side of our business. You will be responsible for analyzing large, complex datasets and identify meaningful patterns that lead to actionable recommendations. You will be performing thorough testing and validation of models, and support various aspects of the business with data analytics. Ability to do statistical modeling, build predictive models and leverage machine learning algorithms. This position will combine the typical Data Scientist math and analytical skills, with research, advanced business, communication, and presentation skills. Primary job location is in Sacramento, but work-from-home option is available.  Qualifications Bachelors, MS or PhD in a relevant field (Computer Science, Engineering, Statistics, Physics, Applied Math) Experience in R and or Python is preferred '"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmings[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Data Science Engineer, Mintel Futures is a core part of Mintels data science team that will have the opportunity to work on a wide array of initiatives across varying aspects of Mintels business and data. This individual will help manage the full analytics lifecycle of advanced projects; help to identify new, impactful ways to apply machine learning to Mintels data; work alongside data scientists and business stakeholders to implement solutions that provide valuable insights; and aide in the design and development of a modern data analytics environment.  What You Will Do:  Play an integral role in shaping the underlying technology environment for Mintels fast growing team of data scientists and data analysts Assist in the acquisition and management of a variety of data sources for large-scale analysis Identify opportunities for predictive modeling or other machine learning techniques and experiment with solutions that focus on adding value to our clients and analysts Work alongside software engineers and other data scientists to ensure the proper deployment, management and monitoring of machine learning models and or other data pipelines in Mintels production platforms Grow the technical and engineering capabilities of other data scientists and data analysts on the team Develop engineering best practices, documentation and process flows that facilitate collaboration and knowledge transfer Continually learn - as a part of a fluid, innovation focused team, you will stay current on emerging data science and data engineering technologies   What We Are Looking For:  3+ years professional experience with building data focused solutions (integrations, pipelines, data warehousing, etc.) 1+ years professional experience as a data scientist or machine learning engineer preferred and or having demonstrable analytical capability and working knowledge of data science principles Proficient engineer with the ability to lead the deployment of machine learning or other analytical models Expert level SQL skills and expert level proficiency in at least one programming language (Python, C++, Java, etc.) Strong communication skills with the ability to converse with both technical and non-technical stakeholders Team player with a collaborative nature Strong work ethic with an inherent sense of ownership and responsibility Experience building data solutions in at least one public cloud environment, AWS or GCP preferred Advanced degree holder in a STEM or related quantitative discipline preferred Equal Opportunity Employer: Race Color Sex Sexual Orientation Gender Identity Religion National Origin Disability Vets '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmings[261]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
